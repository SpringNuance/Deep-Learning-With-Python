{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "a1e60d4781ce79a440b2816f0ba2dda2",
     "grade": false,
     "grade_id": "cell-6cd1a9ba5a4776fe",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "<h1><center>Transfer Learning</center></h1>\n",
    "\n",
    "<br>\n",
    "<center><font size=\"3\">This notebook is a part of teaching material for CS-EJ3311 - Deep Learning with Python</font></center>\n",
    "<center><font size=\"3\">24.10.-11.12.2022</font></center>\n",
    "<center><font size=\"3\">Aalto University & FiTech.io</font></center>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "deletable": false,
    "editable": false,
    "id": "RyE60bplfanb",
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "6f3d574fc190aa811a4a99ccb3d5d190",
     "grade": false,
     "grade_id": "cell-9bd5c09dac49b7d3",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "Assume you want to build an app that distinguishes between different dog breeds. This can be modeled as a classification problem which we can solve using a deep neural network. Indeed, we could train a deep neural network to predict the dog breed based on a large set of labeled images. The problem is that the number of labeled images required for accurate training scales with the number of parameters of the deep net. It might well be that we do not have enough training images for some (rare) breeds.\n",
    "\n",
    "The idea of transfer learning is to exploit similarities between different machine learning problems. Loosely speaking, transfer learning allows borrowing statistical power from related problems for which we can collect more labeled data than for the (\"target\") problem at hand. \n",
    "\n",
    "For the dog breed classification problem, such a similar problem could be the classification of images as dog or cat. We might have access to large image databases of dog and cat images so we can reliably tune the weights of a deep net. If we have found weights for a deep net that allows distinguishing between dog and cat images, it might be a good starting point for adjusting the weights to further distinguish between different dog breeds. \n",
    "\n",
    "## Learning goals \n",
    "\n",
    "- to understand transfer learning and motivation for using it\n",
    "- to learn main transfer learning strategies \n",
    "- to learn how to use transfer learning with pretrained CNN models\n",
    "\n",
    "\n",
    "## Additional Materials\n",
    "\n",
    "- Chapter 5.3 of \"Deep Learning with Python\" by F.Chollet. \n",
    "- Chapter 11 \"Transfer learning with Keras\" of \"Hands-On Machine Learning with Scikit-Learn, Keras, and TensorFlow\" by Aurélien Géron. \n",
    "\n",
    "\n",
    "\n",
    "- [A comprehensive guide to Transfer Learning](https://towardsdatascience.com/a-comprehensive-hands-on-guide-to-transfer-learning-with-real-world-applications-in-deep-learning-212bf3b2f27a)\n",
    "- [A Survey on Transfer Learning](https://www.cse.ust.hk/~qyang/Docs/2009/tkde_transfer_learning.pdf)\n",
    "- [Transfer Learning, Andrew Ng](https://www.youtube.com/watch?v=yofjFQddwHE)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "deletable": false,
    "editable": false,
    "id": "YY4JQWZ_fani",
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "60461ab6d9d550edf1cf7ba0547540f9",
     "grade": false,
     "grade_id": "cell-8f2ca0bb0aa7ffbe",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    " # What is Transfer Learning ?\n",
    " \n",
    "Transfer learning is a machine learning technique in which a model trained for one particular task is used as a starting point for a training model for another task. Transfer learning enables us to utilize the knowledge (such as learned weights, features) from previously learned tasks and apply it to the new, but related task.  \n",
    "\n",
    "\n",
    "For example, for the image classification task certain low-level features, such as edges, shapes, corners, and intensity, do not appears to be specific to a particular dataset or particular task. Such learned features can be shared across different image classification problems, thus enabling knowledge transfer among them. The following figure demonstrates the difference between traditional machine learning and transfer learning.\n",
    "\n",
    "<figure> <img src=\"../../../coursedata/TransferLearning/Transfer_learning.png\" width=800 alt=\"drawing\"/ align='middle'/></figure>\n",
    "\n",
    "<figcaption style=\"text-align:center\" ><a href=https://towardsdatascience.com/a-comprehensive-hands-on-guide-to-transfer-learning-with-real-world-applications-in-deep-learning-212bf3b2f27a > Image source </figcaption>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "deletable": false,
    "editable": false,
    "id": "nWwYoZlXfanj",
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "f0a92f11bf9f73f5b042457b99d2919c",
     "grade": false,
     "grade_id": "cell-ad95ccb1989364a1",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "# Why Transfer Learning?\n",
    "Deep learning models are data-hungry - they need many training examples to learn the parameters of the network. This is one of the limiting aspects of deep neural networks and that is why transfer learning comes in handy. Transfer learning is a common and highly effective approach to train the model on a small image dataset by utilizing **pre-trained models**.  Furthermore, transfer learning helps to save training time, because the model is not trained from scratch. \n",
    "\n",
    "**Pre-trained model** is a deep learning architecture that is trained over a large dataset. Such models are trained for thousands of hours for a given benchmark dataset and all the parameters in the networks are learned. There are numbers of such pre-trained models available and anyone can use them depending on the particular problem.\n",
    "\n",
    "Few examples of pre-trained models are:\n",
    "\n",
    "- **For Computer Vision tasks**\n",
    "    - VGG-16\n",
    "    - VGG-19\n",
    "    - Inception V3\n",
    "    - XCeption\n",
    "    - ResNet-50\n",
    "    - MobileNet\n",
    "\n",
    "- **For Natural Language Processing task**\n",
    "    - Word2Vec\n",
    "    - GloVe\n",
    "    - FastText\n",
    "    - Universal Sentence Encoder by Google\n",
    "    - Bidirectional Encoder Representations from Transformers (BERT) by Google"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "38385ec25c233b60129ebf364d26d4f5",
     "grade": false,
     "grade_id": "cell-a6c4fd511a726942",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "# Key considerations for Transfer Learning\n",
    "\n",
    "To effectively apply transfer learning we need to answer three main questions:\n",
    "\n",
    "-  **What to transfer**: While applying transfer learning we need to understand what knowledge is common between the source and target task. We try to seek answers on what knowledge is specific to the source task and what can be transferred from the source task to the target task that will help improve the performance of the target task. \n",
    "-  **When to transfer**: We should apply transfer learning only when source and target domain are related. When the source and target domains are not related at all, applying transfer learning degrades target task performance. This type of transfer is called Negative Transfer. \n",
    "- **How to transfer**: Once we have answers to what to transfer and when to transfer, we can proceed to identify the actual ways of transferring the knowledge across domains/tasks. \n",
    "\n",
    "**So, when does transfer learning makes sense?** \n",
    "\n",
    "If we are trying to learn from **Task A** and transfer knowledge to **Task B**, transfer learning is useful in the following scenario:\n",
    "- Task A and B have the similar input, e.g both have images as input. \n",
    "- There is a lot more data for Task A than Task B.\n",
    "- Low-level features from A could be helpful in learning task B."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "deletable": false,
    "editable": false,
    "id": "A3Rr6EB5fank",
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "6be33712aeaadc3b8f81be09f7567ebb",
     "grade": false,
     "grade_id": "cell-154482314287b36f",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "# Transfer Learning Strategies\n",
    "There are two common ways to use pre-trained models:\n",
    "\n",
    "1. To use a pre-trained model as a feature extractor\n",
    "2. To fine-tune the pre-trained model \n",
    "\n",
    "### Pre-trained Models as a Feature Extractors\n",
    "\n",
    "A convolutional neural network consists of two parts: the first part is the series of convolutional and pooling layers, and the second part being densely connected layers. The first part is called **convolutional base** and the second - **classification head or classifier**. The main idea of using the pre-trained model as a feature extractor is to remove a fully connected layers (classification head) of the pre-trained model and use only a convolutional base to extract the features from new images.\n",
    "\n",
    "\n",
    "These extracted features will be used to train a new classifier for a new task. In this case, we do not retrain the pre-trained model or part of it (this is called **freezing** the network), but we only train the layers of the new classification head. In other words, the model will only have to learn the weights of the few new dense layers, that are on the top of the pre-trained model.\n",
    "The figure below demonstrates the concept of feature extraction from a pre-trained model and following training of a classifier on top of it. \n",
    "\n",
    "\n",
    "For example, if we have a pre-trained model trained on source data like the ImageNet database (over 14 million images), we chop off the densely connected layers and use this convolutional base to extract the feature from target data (i.e data for new classification task). Specifically, this means to use the output of the convolutional base for training the new (target) model.\n",
    "\n",
    "<br>\n",
    "<figure>\n",
    "    <img src=\"../../../coursedata/TransferLearning/feature_extract.png\" alt=\"drawing\"/ align='middle'/>\n",
    "</figure>\n",
    "\n",
    "\n",
    "###  Fine-tuning the pre-trained model \n",
    "In this case, we do not just replace and retrain the classifier head, i.e fully connected layers, but we also selectively re-train some of the top layers used for feature extraction in the pre-trained model. This process is called **fine-tuning** because it slightly adjusts the more abstract representations of the pre-trained model, in order to make them relevant for the problem at hand.\n",
    "\n",
    "<br>\n",
    "<figure>\n",
    "    <img src=\"../../../coursedata/TransferLearning/fine_tune.png\" alt=\"drawing\"/ align='middle'/>\n",
    "</figure>\n",
    "\n",
    "### Deciding which transfer learning strategy to use \n",
    "Two different transfer learning strategies were presented above. But how do we decide which one to use? The decision is based on two factors: the size of the target (new) dataset (small or big), and its similarity to the source (original) dataset (e.g. ImageNet). Let's discuss four common scenarios and how to navigate among them when choosing a transfer learning strategy.\n",
    "\n",
    "**1. size of the target dataset is small and similar to the source dataset:** In this case, since the size of the new dataset is low, fine-tuning can lead to overfitting. As target data is similar to source data, we use the pre-trained model as a feature extractor while changing the output layer according to the new classification task.\n",
    "\n",
    "**2. The size of the target dataset is small and dissimilar to source data:** In this case we fine-tune the last layers (including some layers of the convolutional block) while freezing the top layers.\n",
    "\n",
    "\n",
    "**3. The size of the target dataset is large and similar to source data:** In such a scenario, the best option would be to fine-tune through the complete network of the pre-trained models with a small learning rate. Since the target dataset is large, there is less concern about overfitting.\n",
    "\n",
    "\n",
    "**4. The size of the target dataset is large and dissimilar to source data:** Since the target dataset is large, we can train the neural network from scratch according to our data. However, in practice, it is very often still beneficial to initialize with weights from a pre-trained model.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "deletable": false,
    "editable": false,
    "id": "o7c3pwr9fanl",
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "1dcbe53edab16d67029ae1ba3a11711b",
     "grade": false,
     "grade_id": "cell-d3fc5d3696ea0390",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "# Implementing Transfer Learning with Pre-trained CNN Model\n",
    "\n",
    "We will be using VGG-16 pre-trained model, created by the Visual Geometry Group at the University of Oxford, which specializes in building very deep convolutional networks for large-scale visual recognition.\n",
    "We will implement both transfer learning strategies, i.e \n",
    "- Using a pre-trained model as a feature extractor\n",
    "- Fine-tuning the pre-trained model\n",
    "    \n",
    "First, let's have a quick introduction to the VGG-16 pre-trained model. \n",
    "\n",
    "### VGG-16 model\n",
    " \n",
    "The VGG-16 model is a 16-layer (convolution and fully connected) network built on the **ImageNet** database. ImageNet (<a href='http://www.image-net.org/challenges/LSVRC/'> ImageNet Large Scale Visual Recognition Challenge</a> , or ILSVRC for short) is a image classification challenge where the goal is to train a model that can correctly classify an input image into 1,000 separate object categories. VGG-16 model was built by Karen Simonyan and Andrew Zisserman and described in their paper  <a href='https://arxiv.org/abs/1409.1556'>\"Very Deep Convolutional Networks for Large-Scale Image Recognition\"</a>. This model was trained on the ImageNet dataset (14 million labeled images and 1000 different classes). \n",
    "The architecture of the VGG-16 model is similar to what we used before but much deeper with tens of thousands of parameters.\n",
    "\n",
    "\n",
    "<figure>\n",
    "    <img src=\"../../../coursedata/TransferLearning/vgg16.png\" alt=\"drawing\"/>\n",
    "</figure>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "a0222dad7703d592702812ef21cfc069",
     "grade": false,
     "grade_id": "cell-f5a30bfd956915c2",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "<div class=\" alert alert-danger\">\n",
    "    <h3><center>WARNING</center></h3>\n",
    "        \n",
    "For this notebook we do not check the models' performances (i.e. accuracy), as the models' training time is quite long. Instead, for grading we will check if the models' architectures are correct.  \n",
    "    \n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "deletable": false,
    "editable": false,
    "id": "ZjHq2832fanm",
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "0d7bda39ed343ce17aecf839e906db24",
     "grade": false,
     "grade_id": "cell-283f41d7368c5e02",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "### Dataset\n",
    "\n",
    "We will use part of the [Cats and Dogs Dataset](https://www.microsoft.com/en-us/download/details.aspx?id=54765) as described in the notebook \"4_Regularization/optional1_TensorFlowData.ipynb\". You do not need to understand how to use tf.data module in details, as data preparation will be done for you. \n",
    "\n",
    "The data consist of color images of cats and dogs that we resize to IMG_SIZE (defined below), resulting in input shape (IMG_SIZE, IMG_SIZE, 3). We will build several CNN models to do binary (labels are {\"cat\", \"dog\"}) classification of images. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "b5fa386704c8bdff212d1fa970044710",
     "grade": false,
     "grade_id": "cell-78e241a670a07677",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "<div class=\"info\">\n",
    "    <div  class=\"info-title\"><i class=\"fa fa-info-circle\" aria-hidden=\"true\"></i>&nbsp;How to use tf.data.Dataset generators</div><br>\n",
    "    <div class=\"wrap-up-content\"> \n",
    "        In this notebook we use tf.data.Dataset objects train_ds, val_ds, test_ds, which when called, return a tuple of (inputs, labels). In our case returned inputs are of shape (BATCH_SIZE, IMG_SIZE, IMG_SIZE, 3).<br>\n",
    "     \n",
    "       \n",
    "We use  tf.data.Dataset generators as:\n",
    "        \n",
    "```python\n",
    "        model.fit(train_ds, validation_data=val_ds, ...)\n",
    "        model.evaluate(test_ds)\n",
    "        \n",
    "```\n",
    "</div>   \n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# set trainig=False when validating or submitting notebook\n",
    "# and set training=True, when training network\n",
    "training=False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "41e85ad5eb9d63ddbc51e03610e98650",
     "grade": true,
     "grade_id": "cell-bd52d73b07d6f321",
     "locked": true,
     "points": 0,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "# this hidden cell is for setting flag training=False\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "deletable": false,
    "editable": false,
    "id": "h2q8pusCfanc",
    "nbgrader": {
     "cell_type": "code",
     "checksum": "ab5523cb3470b2174b7764c26dc97dc2",
     "grade": false,
     "grade_id": "cell-fc3374348615c350",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>\n",
       "@font-face {\n",
       "  font-family: 'Sanchez';\n",
       "  src: url('https://fonts.googleapis.com/css?family=Sanchez:400italic,400');\n",
       "}\n",
       "\n",
       "@import url('https://fonts.googleapis.com/css2?family=Sanchez&display=swap');\n",
       "\n",
       "* {\n",
       "  margin: 0;\n",
       "  padding: 0;\n",
       "  box-sizing: border-box;\n",
       "}\n",
       "\n",
       "*,\n",
       "*:before,\n",
       "*:after {\n",
       "\tbox-sizing: inherit;\n",
       "}\n",
       "\n",
       "body {\n",
       "font-family: -apple-system, BlinkMacSystemFont, \"Segoe UI\", Roboto, Helvetica,\n",
       "    Arial, sans-serif, \"Apple Color Emoji\", \"Segoe UI Emoji\", \"Segoe UI Symbol\";\n",
       "}\n",
       "\n",
       ".title-container {\n",
       "  text-align: left;\n",
       "}\n",
       "\n",
       ".title {\n",
       "  font-weight: 600;\n",
       "}\n",
       "\n",
       ".subtitle {\n",
       "  margin: 10px 0px;\n",
       "  color: #888888;\n",
       "  font-size: 25px;\n",
       "  transition: all 0.5s;\n",
       "}\n",
       "\n",
       ".main-container {\n",
       "  padding: 15px;\n",
       "}\n",
       "\n",
       ".card-container {\n",
       "  display: flex;\n",
       "  flex-wrap: wrap;\n",
       "  justify-content: space-between;\n",
       "}\n",
       "\n",
       ".card {\n",
       "  margin: 20px;\n",
       "  padding: 20px;\n",
       "  width: 100%;\n",
       "  min-height: 200px;\n",
       "  display: grid;\n",
       "  grid-template-columns: 1fr 1fr 1fr;\n",
       "  gap: 10px;\n",
       "  border-radius: 10px;\n",
       "  box-shadow: 0px 6px 10px rgba(0, 0, 0, 0.25);\n",
       "  transition: all 0.5s;\n",
       "}\n",
       "\n",
       ".card.small {\n",
       "  width: 50%;\n",
       "  min-height: 100px;\n",
       "  grid-template-columns: 1fr 1fr;\n",
       "}\n",
       "\n",
       ".card:hover {\n",
       "  box-shadow: 0px 6px 10px rgba(0, 0, 0, 0.4);\n",
       "  transform: scale(1.01);\n",
       "}\n",
       "\n",
       ".card__title {\n",
       "  grid-columnn-start: 1;\n",
       "  grid-columnn-end: -1;\n",
       "  font-weight: 400;\n",
       "  color: #ffffff;\n",
       "}\n",
       "\n",
       ".test-input {\n",
       "  grid-column-start: 1;\n",
       "  grid-column-end: 2;\n",
       "  color: #40413e;\n",
       "}\n",
       "\n",
       ".test-output {\n",
       "  grid-column-start: 2;\n",
       "  grid-column-end: 3;\n",
       "  color: #40413e;\n",
       "}\n",
       "\n",
       ".test-expected-output {\n",
       "  grid-column-start: 3;\n",
       "  grid-column-end: 4;\n",
       "  color: #40413e;\n",
       "}\n",
       "\n",
       ".card-failure {\n",
       "  background: radial-gradient(#fbc1cc, #fa99b2);\n",
       "}\n",
       "\n",
       ".card-failure .card__title::before {\n",
       "    display: inline-block;\n",
       "    margin-right: 5px;\n",
       "    font-style: normal;\n",
       "    font-variant: normal;\n",
       "    text-rendering: auto;\n",
       "    -webkit-font-smoothing: antialiased;\n",
       "    font-family: \"Font Awesome 5 Free\";\n",
       "    font-weight: 900;\n",
       "    content: \"\\f057\";\n",
       "}\n",
       "\n",
       ".card-success {\n",
       "  background: radial-gradient(#60efbc, #58d5c9);\n",
       "}\n",
       "\n",
       ".card-success .card__title::before {\n",
       "    display: inline-block;\n",
       "    margin-right: 5px;\n",
       "    font-style: normal;\n",
       "    font-variant: normal;\n",
       "    text-rendering: auto;\n",
       "    -webkit-font-smoothing: antialiased;\n",
       "    font-family: \"Font Awesome 5 Free\";\n",
       "    font-weight: 900;\n",
       "    content: \"\\f058\";\n",
       "}\n",
       "\n",
       ".card-info {\n",
       "  background: radial-gradient(#1fe4f5, #3fbafe);\n",
       "}\n",
       "\n",
       "@media (max-width: 1600px) {\n",
       "  .card-container {\n",
       "    justify-content: center;\n",
       "  }\n",
       "}\n",
       "\n",
       ".code-block {\n",
       "  padding: 5px;\n",
       "  background-color: #f3f7f7;\n",
       "  color: black;\n",
       "  border-radius: 10px;\n",
       "  box-shadow: 0px 6px 10px rgba(0, 0, 0, 0.25);\n",
       "}\n",
       "\n",
       "details {\n",
       "\tfont-size: 1rem;\n",
       "\tbox-shadow: 0 10px 15px -5px rgba(0, 0, 0, 0.1),\n",
       "\t\t0 10px 10px -5px rgba(0, 0, 0, 0.04);\n",
       "\twidth: 100%;\n",
       "\tbackground: #ffffff;\n",
       "\tborder-radius: 10px;\n",
       "\tposition: relative;\n",
       "}\n",
       "\n",
       "details:hover {\n",
       "    cursor: pointer;\n",
       "}\n",
       "\n",
       ".summary-title {\n",
       "    user-select: none;\n",
       "    margin-left: 5px;\n",
       "}\n",
       "\n",
       ".summary-content {\n",
       "    border: 2px solid #0C7B89;\n",
       "    cursor: default;\n",
       "    padding: 1em;\n",
       "    font-weight: 300;\n",
       "    font-size: 15px;\n",
       "    line-height: 1.5;\n",
       "}\n",
       "\n",
       ".wrap-up {\n",
       "    border: 2px solid #B41086;\n",
       "    cursor: default;\n",
       "    padding: 20px;\n",
       "    line-height: 1.5;\n",
       "    border-radius: 20px\n",
       "}\n",
       "\n",
       ".wrap-up-title {\n",
       "    font-size:20px;\n",
       "    color: #B41086;\n",
       "    font-weight: bold\n",
       "}\n",
       "\n",
       ".wrap-up-content {\n",
       "    font-size:14px;\n",
       "    color: black;\n",
       "}\n",
       "\n",
       ".info {\n",
       "    background-color: white;\n",
       "    border: 2px solid #0C7B89;\n",
       "    cursor: default;\n",
       "    padding: 10px;\n",
       "    line-height: 1.5;\n",
       "    border-radius: 20px\n",
       "}\n",
       "\n",
       ".info-title {\n",
       "    font-size: 20px;\n",
       "    color: #0C7B89;\n",
       "    font-weight: bold\n",
       "}\n",
       "\n",
       "summary {\n",
       "   color: white;\n",
       "   font-size: large;\n",
       "   font-weight: bold;\n",
       "   padding: 1em;\n",
       "   background-color: #0C7B89;\n",
       "   border-radius: 8px;\n",
       "   list-style: none;\n",
       "}\n",
       "\n",
       "details[open] summary {\n",
       "    border-radius: 8px 8px 0 0;\n",
       "}\n",
       "\n",
       "details[open] summary::before {\n",
       "  transform: rotate(90deg);\n",
       "  font-family: \"Font Awesome 5 Free\";\n",
       "  padding-right: 5px;\n",
       "}\n",
       "\n",
       "details summary::before {\n",
       "  position: absolute;\n",
       "  will-change: transform;\n",
       "  transition: transform 300ms ease;\n",
       "  font-family: \"Font Awesome 5 Free\";\n",
       "  color: #fff;\n",
       "  font-size: 1.1rem;\n",
       "  content: \"\\f105\";\n",
       "  left: 0;\n",
       "  display: inline-block;\n",
       "  width: 1.6rem;\n",
       "  text-align: center;\n",
       "  padding-right: 5px;\n",
       "}\n",
       "\n",
       "summary:focus {\n",
       "  outline: none;\n",
       "}\n",
       "\n",
       "summary::-webkit-details-marker {\n",
       "    display: none;\n",
       "}\n",
       "\n",
       ".ludwig {\n",
       "  position: relative;\n",
       "  padding-left: 1em;\n",
       "  border-left: 0.2em solid lighten( hsl(200, 40, 10), 40%);\n",
       "  font-family: 'Roboto', serif;\n",
       "  font-size: 1.3em;\n",
       "  line-height: 1.5em;\n",
       "  font-weight: 100;\n",
       "}\n",
       "\n",
       ".ludwig::before, .ludwig::after {\n",
       "  content: '\\201C';\n",
       "  font-family: 'Sanchez';\n",
       "  color: lighten( hsl(200, 40, 10), 40%);\n",
       "}\n",
       "\n",
       ".ludwig::after {\n",
       "  content: '\\201D';\n",
       "}\n",
       "\n",
       ".blockquote-container {\n",
       "  margin: 2em auto;\n",
       "}\n",
       "\n",
       "blockquote {\n",
       "  margin-bottom: 3em;\n",
       "}\n",
       "\n",
       "</style>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# import Python packages and libraries\n",
    "import tensorflow as tf \n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator \n",
    "import matplotlib.pyplot as plt\n",
    "import pathlib\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "import ssl\n",
    "ssl._create_default_https_context = ssl._create_unverified_context\n",
    "\n",
    "# function to preprocess input for futher feeding into VGG16 network\n",
    "from tensorflow.keras.applications.vgg16 import preprocess_input\n",
    "# custom CSS style \n",
    "from utils.styles import load_styles \n",
    "\n",
    "load_styles()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "18c3e72a18a885f5dde0be92c0110e43",
     "grade": false,
     "grade_id": "cell-8bb59f6e91a3b46b",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "CLASS_NAMES = ['cats', 'dogs']\n",
    "BATCH_SIZE = 32\n",
    "IMG_SIZE = 60"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "9bf0c96c10e258afc8f84ca204eb3eaf",
     "grade": false,
     "grade_id": "cell-c97f2670210157ec",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "# custom pre-processing functions for data preparation\n",
    "\n",
    "def load_image(image_path):\n",
    "    # load image\n",
    "    image = tf.io.read_file(image_path)                     # read the image from disk\n",
    "    image = tf.io.decode_jpeg(image, channels=3)            # decode jpeg  \n",
    "    image = tf.image.resize(image, [IMG_SIZE, IMG_SIZE])    # resize\n",
    "    image = preprocess_input(image)                         # preprocess input for feeding into VGG16 network\n",
    "    \n",
    "    # get lable value from path\n",
    "    parts = tf.strings.split(image_path, os.path.sep)  # parse the class label from the file path\n",
    "    one_hot = parts[-2] == CLASS_NAMES                 # select only part with class name and create boolean array\n",
    "    label = tf.argmax(one_hot)                         # get label as integer from boolean array\n",
    "    \n",
    "    return (image, label)\n",
    "\n",
    "\n",
    "def configure_for_performance(ds, shuffle=False):      # chain tf.data.Dataset functions\n",
    "    if shuffle:\n",
    "        ds = ds.shuffle(buffer_size=2000)\n",
    "    ds = ds.batch(batch_size=BATCH_SIZE)\n",
    "    ds = ds.prefetch(buffer_size=AUTOTUNE)\n",
    "    return ds"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "d8729182893d34b6c7ab9771a6b7afc8",
     "grade": false,
     "grade_id": "cell-97e596a4bf4f843f",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "# 1. Training VGG16 model from scratch\n",
    "\n",
    "As a baseline, we can try to train the whole network from scratch. This is not the optimal way to use such a huge model with around 16 million parameters, as it will take a lot of time. In addition, there is a big chance that the network will overfit as we are training a very large network on a small dataset.\n",
    "\n",
    "Thus, below we just learn how to build such model, without actually training it.\n",
    "\n",
    "\n",
    "<div class=\" alert alert-danger\">\n",
    "        <h3><center>WARNING</center></h3>\n",
    "        \n",
    "Do not train this model on Jupyter Hub as it takes hours, but if you are curious, you can run the whole network on GPU and try different optimizers, learning rates, etc. to improve the predictions. You may also use fewer epochs to run.\n",
    "    \n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "d7df594b81a6259dfaca6677ef55accc",
     "grade": false,
     "grade_id": "cell-8dce1258cd969588",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "The input should be preprocessed before passing to the pre-trained VGG16 network.\\\n",
    "Previously we scaled images from 0-255 to 0-1, but as the VGG16 network was trained on input scaled differently, we should preprocess our input in the same way. Specifically, the VGG16 network was trained on zero-centered by mean pixel (rather than mean image) subtraction. Namely, the following BGR values should be subtracted: [103.939, 116.779, 123.68]. See the original paper for [more detail](https://arxiv.org/abs/1409.1556)\n",
    "\n",
    "Readily available function `preprocess_input` can be imported from tensorflow:\n",
    "\n",
    "`from tensorflow.keras.applications.vgg16 import preprocess_input`\n",
    "\n",
    "We add `preprocess_input` function to custom function `load_image` (see code above)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "820c26bf620f13a721e8071fc1413c02",
     "grade": false,
     "grade_id": "cell-11601fd4cb650549",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "<div class=\" alert alert-warning\">\n",
    "    <h3><b>Student task. </b>Build a model from scratch.</h3>\n",
    "    \n",
    "Your task is:\n",
    "    \n",
    "1. to import the VGG16 convolutional base (**without** learned weights). Store in a variable `conv_base`.\n",
    "2. add classification head with one hidden layer. Store stacked convolutional base and classification head in variable `model`.\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "6ddee0bc79e2797e786850a6a2067834",
     "grade": false,
     "grade_id": "cell-292e39cfb3a3166e",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "<div class=\" alert alert-warning\">\n",
    "    <i>1. Import the VGG16 convolutional base.</i>\n",
    "    \n",
    "    \n",
    "    \n",
    "We can import the pre-trained VGG16 model from Keras with `from tensorflow.keras.applications import VGG16`. \n",
    "Other available models: https://www.tensorflow.org/api_docs/python/tf/keras/applications\n",
    "    \n",
    "There are few arguments passed to the constructor:\n",
    "\n",
    "- **weights**, to specify which weight checkpoint to initialize the model from. Specify `None`. This means we imported only the architecture of the VGG16 model without pre-trained weights. \n",
    "- **include_top**, which refers to include or not including the densely connected classifier on top of the network. Set it `False`, thus we chop off densely connected classifier from VGG16 model and retained only its convolutional base. \n",
    "- **input_shape**, the shape of the image tensors (img height, img width, channels) that we will feed to the network. We already set image size in variable `IMG_SIZE`.\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "669d9e93d5ce646d5dac8a134d81592b",
     "grade": false,
     "grade_id": "cell-536fd96d2d6c26be",
     "locked": false,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-11-30 02:18:31.502725: I tensorflow/core/platform/cpu_feature_guard.cc:142] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  SSE4.1 SSE4.2 AVX AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    }
   ],
   "source": [
    "# YOUR CODE HERE\n",
    "# raise NotImplementedError()\n",
    "\n",
    "# import model from tensorflow.keras.applications\n",
    "from tensorflow.keras.applications import VGG16\n",
    "\n",
    "# pass arguments\n",
    "conv_base = VGG16(weights=None, include_top=False, input_shape=(IMG_SIZE, IMG_SIZE, 3))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "c788a2e83d5991349324ee77b8e3d198",
     "grade": false,
     "grade_id": "cell-b376e3888dc481c9",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "<div class=\"info\">\n",
    "    <div  class=\"info-title\"><i class=\"fa fa-info-circle\" aria-hidden=\"true\"></i>&nbsp; Info</div><br>\n",
    "    <div class=\"wrap-up-content\"> Ignore warning messages:\n",
    "        <ul>\n",
    "        <li> \"This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) ...\"  </li> \n",
    "         <li>  \"None of the MLIR Optimization Passes are enabled ...\"  </li> \n",
    "        </ul>\n",
    "</div>   \n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "32c4d205d1f47b01c0cccec51550815a",
     "grade": false,
     "grade_id": "cell-12612a20a1dc6364",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sanity checks passed!\n"
     ]
    }
   ],
   "source": [
    "# Sanity checks \n",
    "assert len(conv_base.layers)==19, \"There should be 19 layers!\"\n",
    "print(\"Sanity checks passed!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "757271f434d7fd26f5f15425b0125b16",
     "grade": true,
     "grade_id": "cell-53ee649971bf82c5",
     "locked": true,
     "points": 0.25,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "# this cell is for tests\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "cba00f1b96894dad644eece42f0f75da",
     "grade": true,
     "grade_id": "cell-b3a2887765d65b2b",
     "locked": true,
     "points": 0.25,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "# hidden test\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "ce982f7c23e36066f6f53459e97aee55",
     "grade": true,
     "grade_id": "cell-ffbb0efdcdd3d392",
     "locked": true,
     "points": 0.25,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "# hidden test\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "8c051636fdc1ff4d97201f01a6842ecb",
     "grade": false,
     "grade_id": "cell-1edaa0b57bfe939b",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"vgg16\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_1 (InputLayer)         [(None, 60, 60, 3)]       0         \n",
      "_________________________________________________________________\n",
      "block1_conv1 (Conv2D)        (None, 60, 60, 64)        1792      \n",
      "_________________________________________________________________\n",
      "block1_conv2 (Conv2D)        (None, 60, 60, 64)        36928     \n",
      "_________________________________________________________________\n",
      "block1_pool (MaxPooling2D)   (None, 30, 30, 64)        0         \n",
      "_________________________________________________________________\n",
      "block2_conv1 (Conv2D)        (None, 30, 30, 128)       73856     \n",
      "_________________________________________________________________\n",
      "block2_conv2 (Conv2D)        (None, 30, 30, 128)       147584    \n",
      "_________________________________________________________________\n",
      "block2_pool (MaxPooling2D)   (None, 15, 15, 128)       0         \n",
      "_________________________________________________________________\n",
      "block3_conv1 (Conv2D)        (None, 15, 15, 256)       295168    \n",
      "_________________________________________________________________\n",
      "block3_conv2 (Conv2D)        (None, 15, 15, 256)       590080    \n",
      "_________________________________________________________________\n",
      "block3_conv3 (Conv2D)        (None, 15, 15, 256)       590080    \n",
      "_________________________________________________________________\n",
      "block3_pool (MaxPooling2D)   (None, 7, 7, 256)         0         \n",
      "_________________________________________________________________\n",
      "block4_conv1 (Conv2D)        (None, 7, 7, 512)         1180160   \n",
      "_________________________________________________________________\n",
      "block4_conv2 (Conv2D)        (None, 7, 7, 512)         2359808   \n",
      "_________________________________________________________________\n",
      "block4_conv3 (Conv2D)        (None, 7, 7, 512)         2359808   \n",
      "_________________________________________________________________\n",
      "block4_pool (MaxPooling2D)   (None, 3, 3, 512)         0         \n",
      "_________________________________________________________________\n",
      "block5_conv1 (Conv2D)        (None, 3, 3, 512)         2359808   \n",
      "_________________________________________________________________\n",
      "block5_conv2 (Conv2D)        (None, 3, 3, 512)         2359808   \n",
      "_________________________________________________________________\n",
      "block5_conv3 (Conv2D)        (None, 3, 3, 512)         2359808   \n",
      "_________________________________________________________________\n",
      "block5_pool (MaxPooling2D)   (None, 1, 1, 512)         0         \n",
      "=================================================================\n",
      "Total params: 14,714,688\n",
      "Trainable params: 14,714,688\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# print summary of convolutional base\n",
    "conv_base.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "2cd921c658ff604fede8a1202a29f333",
     "grade": false,
     "grade_id": "cell-c0500518552a6dde",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "   We can see that the last activation feature map (output from block5_pool)  in the VGG-16 model gives features (output) of shape (1,1,512). These features are then flattened and fed to our own fully connected deep neural network classifier to classify between \"cat\" and \"dog\" classes. Also, the number of trainable parameters in the convolutional base model is more than 14 million."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "c776fe9c0595b7641c57f0e0c259655b",
     "grade": false,
     "grade_id": "cell-dd1fc7fd837d536c",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "<div class=\" alert alert-warning\">\n",
    "    <i>2. Build a model.</i>\n",
    "    \n",
    "    \n",
    "Build a final model. The model should consist of:\n",
    "- conv base\n",
    " \n",
    "and classification head:\n",
    "\n",
    "- `tf.keras.layers.Flatten()` layer to reshape array  (num_samples,1,1,512) to (num_samples,512).\n",
    "- one hidden dense layer with 128 unit and activation = \"relu\".\n",
    "- output layer \n",
    "    \n",
    "Choose the number of neurons and activation function of the output layer appropriate to the **binary classification** task.\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "e1b25f05a2bf7ca27992430bcaa13084",
     "grade": false,
     "grade_id": "cell-c5a43e6bc6d2b02d",
     "locked": false,
     "schema_version": 3,
     "solution": true,
     "task": false
    },
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "vgg16 (Functional)           (None, 1, 1, 512)         14714688  \n",
      "_________________________________________________________________\n",
      "flatten (Flatten)            (None, 512)               0         \n",
      "_________________________________________________________________\n",
      "dense (Dense)                (None, 128)               65664     \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 2)                 258       \n",
      "=================================================================\n",
      "Total params: 14,780,610\n",
      "Trainable params: 14,780,610\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model = tf.keras.models.Sequential()\n",
    "\n",
    "# YOUR CODE HERE\n",
    "# raise NotImplementedError()\n",
    "\n",
    "# add convolutional base as layer \n",
    "model.add(conv_base)\n",
    "\n",
    "# add classification head \n",
    "model.add(tf.keras.layers.Flatten())\n",
    "model.add(tf.keras.layers.Dense(128, activation=\"relu\"))\n",
    "model.add(tf.keras.layers.Dense(2, activation=\"sigmoid\"))\n",
    "\n",
    "# display model summary\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "e5dda91178fa8b379f2e9ff7a97442f7",
     "grade": false,
     "grade_id": "cell-6bb0222b47ff906a",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sanity checks passed!\n"
     ]
    }
   ],
   "source": [
    "# Sanity checks \n",
    "assert len(model.layers) == 4, \"There should be 4 layers!\"\n",
    "\n",
    "print(\"Sanity checks passed!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "faafc45f31e7634ad4150f062c88d3dc",
     "grade": true,
     "grade_id": "cell-0386dd9148427559",
     "locked": true,
     "points": 1,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "# this cell is for tests\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "385b65d4cde851a60d78ebaa9791dd44",
     "grade": true,
     "grade_id": "cell-b56a62b961d5f7e8",
     "locked": true,
     "points": 0.25,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "# hidden test\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "47ccd02ef9a6fd7d0e4a2ec3114c8c89",
     "grade": false,
     "grade_id": "cell-57c3168bc753fa84",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "Training this model would result in a plot similar to this:\n",
    "\n",
    "<br>\n",
    "<figure>\n",
    "    <img src=\"../../../coursedata/TransferLearning/R5_1.png\" width=600/ align='middle'/>\n",
    "</figure>\n",
    "\n",
    "You can see that, first, it takes at least 200 epochs until learning reaches a plateau and, second, the model is overfitting. The accuracy for the validation dataset is about 0.80-0.85.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "7234aa7b6c18bac3cfa930470a478c1d",
     "grade": false,
     "grade_id": "cell-da7620ed0899a8a0",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "\n",
    "# 2. Pre-trained VGG16 model as a feature extractor\n",
    "\n",
    "In this part, we freeze pre-trained convolutional base and use it as a feature extractor. One way of combining frozen convolutional base and classification head is to create one model (as you did above).\n",
    "This is convenient when using data augmentation, as you can pass tf.data generators directly to `model.fit()`. Unfortunately, it is time-consuming. Therefore,  we will use the standalone convolutional base as a feature extractor (generate predictions from a pre-trained convolutional base) and we feed these extracted features to the classification head (dense layers). This is much faster than passing all data through the network, but requires extra step to retrieve labels of the images."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "7f5ba52d0c4aa295a2099fcabdbf9942",
     "grade": false,
     "grade_id": "cell-4f7418401ce2615f",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "<div class=\" alert alert-warning\">\n",
    "    <h3><b>Student task. </b>Pre-trained VGG16 as feature extractor.</h3>\n",
    "   \n",
    "Here we make use of the pre-trained VGG16 model and import weights already learned during training on the Imagenet dataset. You need to use a pre-trained model as a feature extractor, i.e implemented as a separate block. This method is very fast and effective when the target dataset is similar to the source dataset. Pre-trained VGG16 convolutional base outputs \"new features\" of our input images, which we will use as input to un-trained classification head.\n",
    " \n",
    "Note, that this time you import convolutional base with argument `weights='imagenet'`.\n",
    "\n",
    "This means that the VGG16 model is imported with pre-trained weights derived from training over the Imagenet database. \n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "d3bf9f6c95ff5260d1a36116dff65b08",
     "grade": false,
     "grade_id": "cell-8f52006de5ed3edf",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "Before we build our feature extractor and classification head, we need to prepare data in the appropriate format.\n",
    "\n",
    "We get output (\"extracted features\") from pre-trained conv base  with a function `model.predict(generator)`. \n",
    "The output is a numpy array and not a tf.data.Dataset object. This output then serves as input to the classification head. There are few things to consider:\n",
    "- input for the classification head is a numpy array (\"extracted features\"), thus we need to feed also labels corresponding to features.\n",
    "- we can access labels from tf.data.Dataset object with function `tf.data.Dataset.take()`. This function will return features and labels for a batch of data. If we want to get labels for all samples, we need to set the `batch_size` parameter of the tf.data.Dataset equal to the total number of samples.\n",
    "- With each call tf.data.Dataset object shuffles data by default. We need to set `shuffle=False` in `tf.data.Dataset.list_files()`, so the order of samples is the same at each call."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "87e676c2b2fee20fcac6a2823ed1658a",
     "grade": false,
     "grade_id": "cell-ff24aacb5b416f82",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "First, let's create tf.data.Dataset object with `shuffle=False` and `batch_size` set to whole train, validation and test sets."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "9f82a43c5ea4d7bc773c91d49131c848",
     "grade": false,
     "grade_id": "cell-7beb479ffab52b0e",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "# path to the dataset\n",
    "base_dir = pathlib.Path.cwd() / '..' / '..' /  '..' / 'coursedata' / 'cats_and_dogs_small'\n",
    "\n",
    "# directories for training,\n",
    "# validation and test sets\n",
    "train_dir = base_dir / 'train' \n",
    "validation_dir =  base_dir / 'validation'\n",
    "test_dir = base_dir / 'test'\n",
    "\n",
    "\n",
    "AUTOTUNE = tf.data.experimental.AUTOTUNE\n",
    "\n",
    "train_ds = tf.data.Dataset.list_files(str(base_dir/'train/*/*.jpg'), shuffle=False)\n",
    "val_ds   = tf.data.Dataset.list_files(str(base_dir/'validation/*/*.jpg'), shuffle=False)\n",
    "test_ds  = tf.data.Dataset.list_files(str(base_dir/'test/*/*.jpg'), shuffle=False)\n",
    "\n",
    "\n",
    "with tf.device('/cpu:0'):\n",
    "    # Set `num_parallel_calls` so multiple images are loaded/processed in parallel.\n",
    "    train_ds = train_ds.map(load_image, num_parallel_calls=AUTOTUNE)\n",
    "    val_ds = val_ds.map(load_image, num_parallel_calls=AUTOTUNE)\n",
    "    test_ds = test_ds.map(load_image, num_parallel_calls=AUTOTUNE)\n",
    "    # batch size is set to the size of the whole set\n",
    "    train_ds = train_ds.batch(batch_size=1997)\n",
    "    val_ds   = val_ds.batch(batch_size=995)\n",
    "    test_ds  = test_ds.batch(batch_size=1000)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "b4d3e106d4ec8507ef4e83977c8f7905",
     "grade": false,
     "grade_id": "cell-49318fca151eb14e",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "With batch size set to the whole train, validation and test sets, we can extract labels with `tf.data.Dataset .take(1)`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "7e27bed252e84205a5613929f624573a",
     "grade": false,
     "grade_id": "cell-8771d02a0727f002",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-11-30 02:18:32.110088: I tensorflow/compiler/mlir/mlir_graph_optimization_pass.cc:185] None of the MLIR Optimization Passes are enabled (registered 2)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of training labels:  1997\n",
      "Number of validation labels:  995\n",
      "Number of test labels:  1000\n"
     ]
    }
   ],
   "source": [
    "def get_labels(ds):\n",
    "    for images, labels in ds.take(1):\n",
    "        return labels\n",
    "\n",
    "# get training labels\n",
    "train_labels = get_labels(train_ds)\n",
    "\n",
    "# get validation labels\n",
    "val_labels = get_labels(val_ds)\n",
    "\n",
    "# get test labels\n",
    "test_labels = get_labels(test_ds)\n",
    "\n",
    "# check number of labels\n",
    "print(\"Number of training labels: \", len(train_labels))\n",
    "print(\"Number of validation labels: \", len(val_labels))\n",
    "print(\"Number of test labels: \", len(test_labels))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "67a0e1284ae60de70175fe07ed870405",
     "grade": false,
     "grade_id": "cell-c48edad84fdb2404",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "For the feature extraction we create new generator functions with `batch_size=32` as a large batch size may lead to memory run-out.\n",
    "\n",
    "Note, that we set `shuffle=False` here too, so the samples returned by the generator will be in the same order as labels. In custom function `configure_for_performance` shuffle set to False by default (see code in the beginning of notebook)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "4384e2fc7f67eb54f9dcfd448c42aea8",
     "grade": false,
     "grade_id": "cell-5c61d9e9e37d3425",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "train_ds = tf.data.Dataset.list_files(str(base_dir/'train/*/*.jpg'), shuffle=False)\n",
    "val_ds   = tf.data.Dataset.list_files(str(base_dir/'validation/*/*.jpg'), shuffle=False)\n",
    "test_ds  = tf.data.Dataset.list_files(str(base_dir/'test/*/*.jpg'), shuffle=False)\n",
    "\n",
    "\n",
    "with tf.device('/cpu:0'):\n",
    "    # Set `num_parallel_calls` so multiple images are loaded/processed in parallel.\n",
    "    train_ds = train_ds.map(load_image, num_parallel_calls=AUTOTUNE)\n",
    "    val_ds = val_ds.map(load_image, num_parallel_calls=AUTOTUNE)\n",
    "    test_ds = test_ds.map(load_image, num_parallel_calls=AUTOTUNE)\n",
    "\n",
    "    train_ds = configure_for_performance(train_ds)\n",
    "    val_ds   = configure_for_performance(val_ds)\n",
    "    test_ds  = configure_for_performance(test_ds)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "ac844d1e22fa050590dd60afb75c8ebc",
     "grade": false,
     "grade_id": "cell-9338134185aa8745",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "<div class=\" alert alert-warning\">\n",
    "    <h3><b>Student task. </b>Pre-trained VGG16 as feature extractor.</h3>\n",
    "   \n",
    "Your task is to:\n",
    "    \n",
    "1. Load pre-trained convolutional base and freeze all layers.\n",
    "2. Perform feature extraction (make predictions) on generator functions for training, validation, and test sets.\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "e52388322e682f5c0ef4d4b37981a498",
     "grade": false,
     "grade_id": "cell-ae26a68a4c3a3411",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "<div class=\" alert alert-warning\">\n",
    "    <i>1. Load pre-trained convolutional base.</i>\n",
    "    \n",
    "    \n",
    "- Import convolutional base with argument `weights='imagenet'`. Set args `include_top` & `input_shape` as before.\n",
    "\n",
    "This means we imported the VGG16 model with pre-trained weight derived from training over the ImageNet database. \n",
    "- Freeze `conv_base` model defined previously. This ensures that weights of `conv_base` will not change during the training of the model.\n",
    "In Keras, freezing of a network is done by setting its `trainable` attribute to `False` (see Keras tutorial [here](https://keras.io/guides/transfer_learning/#recursive-setting-of-the-trainable-attribute)).\n",
    "</div>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "deletable": false,
    "id": "CYWyfGBkfao2",
    "nbgrader": {
     "cell_type": "code",
     "checksum": "a0d0c3513dcf7cff519304452d64cc38",
     "grade": false,
     "grade_id": "cell-6cd57bfcd2402786",
     "locked": false,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "# YOUR CODE HERE\n",
    "# raise NotImplementedError()\n",
    "\n",
    "# load pre-trained VGG16 conv base from keras\n",
    "conv_base = VGG16(weights=\"imagenet\", include_top=False, input_shape=(IMG_SIZE, IMG_SIZE, 3))\n",
    "\n",
    "# freeze layers\n",
    "conv_base.trainable=False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "94d05a21c1e32900803b5fe6dfbcc076",
     "grade": false,
     "grade_id": "cell-2b98505d99e2ce8d",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sanity check passed!\n"
     ]
    }
   ],
   "source": [
    "# Sanity check\n",
    "\n",
    "assert len(conv_base.layers)==19, \"There should be 19 layers!\"\n",
    "assert conv_base.trainable==False, \"Freeze conv base layers!\"\n",
    "print(\"Sanity check passed!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "18771b23a5e927f397cdc982ba17d396",
     "grade": true,
     "grade_id": "cell-fd49147ed87af9f4",
     "locked": true,
     "points": 0.5,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "# this cell is for tests\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "32bdb2172844126bf61a7b05d70af339",
     "grade": true,
     "grade_id": "cell-33ca855176001178",
     "locked": true,
     "points": 0.5,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "# hidden test\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "9dc3222d4d1e446f530020d3b536fee7",
     "grade": false,
     "grade_id": "cell-7d7c2c4d98de3f82",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "<div class=\" alert alert-info\">\n",
    "    <i>2. Perform feature extraction.</i>\n",
    "    \n",
    "    \n",
    "Below we feed generators (train_ds, val_ds, test_ds) to pre-trained frozen conv base and get extracted features.\n",
    "    \n",
    "We use `model.predict(generator)` function to get output. It may take couple of minutes.\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "81ba4b0765ccfa0ae32de2b3c6718d66",
     "grade": false,
     "grade_id": "cell-1e8e60bfd44f974f",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 8 µs, sys: 2 µs, total: 10 µs\n",
      "Wall time: 19.3 µs\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "if training:\n",
    "    train_features = conv_base.predict(train_ds)\n",
    "    val_features   = conv_base.predict(val_ds)\n",
    "    test_features  = conv_base.predict(test_ds)\n",
    "\n",
    "    print(train_features.shape)\n",
    "    print(val_features.shape)\n",
    "    print(test_features.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "1c40f341b30f88f1f51b54e5865e723d",
     "grade": false,
     "grade_id": "cell-d5fc1e1289ea93f8",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "# Sanity check\n",
    "\n",
    "if training:\n",
    "    assert train_features.shape==(1997, 1, 1, 512), \"Shape of train_features is not correct!\"\n",
    "    assert val_features.shape==(995, 1, 1, 512), \"Shape of val_features is not correct!\"\n",
    "    assert test_features.shape==(1000, 1, 1, 512), \"Shape of test_features is not correct!\"\n",
    "    print(\"Sanity check passed!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "ccb71248c51b59119563e6051376e6fa",
     "grade": false,
     "grade_id": "cell-62717b90275b4636",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "<div class=\" alert alert-warning\">\n",
    "    <h3><b>Student task. </b>Train classification head on extracted features.</h3>\n",
    "   \n",
    "Your task is to:\n",
    "    \n",
    "1. Build a classification head.\n",
    "2. Compile and train classification head.\n",
    "   \n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "f94670ae5cc48904f0027fca1fb989fe",
     "grade": false,
     "grade_id": "cell-28ec083e24a77ea2",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "<div class=\" alert alert-warning\">\n",
    "    <i>1. Build a classification head.</i>\n",
    "    \n",
    "Initialize a model with:\n",
    "    \n",
    "- `Flatten()` layer to flatten input fed to Dense layer. Set `input_shape=(1, 1, 512)` parameter of `Flatten()` layer.\n",
    "- one Dense layer with 128 units and activation=\"relu\".\n",
    "- output layer. Choose the number of neurons and activation function of the output layer appropriate to the binary classification task.\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "deletable": false,
    "id": "TVZAilPrfapG",
    "nbgrader": {
     "cell_type": "code",
     "checksum": "a8768770435c9f8eefc7c703f96e109b",
     "grade": false,
     "grade_id": "cell-7a809c96a04d8b74",
     "locked": false,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_1\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "flatten_1 (Flatten)          (None, 512)               0         \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 128)               65664     \n",
      "_________________________________________________________________\n",
      "dense_3 (Dense)              (None, 2)                 258       \n",
      "=================================================================\n",
      "Total params: 65,922\n",
      "Trainable params: 65,922\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# YOUR CODE HERE\n",
    "# raise NotImplementedError()\n",
    "\n",
    "clf_head = tf.keras.models.Sequential([\n",
    "    tf.keras.layers.Flatten(input_shape=(1,1,512)),\n",
    "    tf.keras.layers.Dense(128, activation=\"relu\"),\n",
    "    tf.keras.layers.Dense(2, activation=\"sigmoid\")\n",
    "])\n",
    "\n",
    "# display model summary\n",
    "clf_head.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "ca59e3d5d5f159197274b2980a486e75",
     "grade": false,
     "grade_id": "cell-7ed5b4df83f93f7f",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sanity check passed!\n"
     ]
    }
   ],
   "source": [
    "# Sanity check\n",
    "\n",
    "assert len(clf_head.layers) == 3, \"There should be 3 layers!\"\n",
    "print(\"Sanity check passed!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "befbbbcf2a012673b4768abe6939f792",
     "grade": true,
     "grade_id": "cell-1c31f8256b3fbf41",
     "locked": true,
     "points": 1,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "# this cell is for tests\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "1d70fb230738641ed6cd605c1f3528a0",
     "grade": false,
     "grade_id": "cell-7c87f339832d99d1",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "<div class=\" alert alert-warning\">\n",
    "    <i>2. Compile and train classification head.</i>\n",
    "    \n",
    "Use loss function and metrics appropriate to the binary classification task. Use RMSprop optimizer with default settings (pass just a string to `optimizer`).\n",
    "\n",
    "Train classification head on extracted features for 50 epochs. Use labels we retrieved earlier (train_labels, val_labels, test_labels). Training accuracy should be around 1.0 and validation/test accuracy about 0.78.\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "d838d0e449531751ca05c672849ec765",
     "grade": false,
     "grade_id": "cell-b41df302db8bec9f",
     "locked": false,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "# compile the model \n",
    "clf_head.compile(optimizer = \"RMSProp\",              \n",
    "                 loss='sparse_categorical_crossentropy',\n",
    "                 metrics='accuracy')\n",
    "\n",
    "# YOUR CODE HERE\n",
    "# raise NotImplementedError()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "db07f9e6f40d9fefc115579227bc2c71",
     "grade": true,
     "grade_id": "cell-e9e6a1b6131504eb",
     "locked": true,
     "points": 0.25,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "# this cell is for tests\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "afda336449a134917ed86a17deda29a3",
     "grade": true,
     "grade_id": "cell-2a9c06f30d58e329",
     "locked": true,
     "points": 0.25,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "# this cell is for tests\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "deletable": false,
    "id": "lW78sT40fapR",
    "nbgrader": {
     "cell_type": "code",
     "checksum": "d350b7236b9a5f911a86d9ea1041bad2",
     "grade": false,
     "grade_id": "cell-afcea11bc0216efc",
     "locked": false,
     "schema_version": 3,
     "solution": true,
     "task": false
    },
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 8 µs, sys: 2 µs, total: 10 µs\n",
      "Wall time: 19.8 µs\n"
     ]
    }
   ],
   "source": [
    "%%time \n",
    "\n",
    "# model training\n",
    "if training:\n",
    "# YOUR CODE HERE\n",
    "# raise NotImplementedError()\n",
    "    \n",
    "    history = clf_head.fit(train_features, train_labels, validation_data=(val_features, val_labels), batch_size=32, epochs=50, verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "c8479b6733637db6bfff0e3e4c18532e",
     "grade": false,
     "grade_id": "cell-c240cf406a4b7fc7",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "# plot training log\n",
    "\n",
    "if training:\n",
    "    test_loss, test_acc = clf_head.evaluate(test_features, test_labels)\n",
    "    print(f'The test set accuracy of model is {test_acc:.2f}')\n",
    "\n",
    "    fig, ax = plt.subplots(1,2, figsize=(10,3))\n",
    "    df_accuracy = pd.DataFrame(history.history).loc[:,['accuracy','val_accuracy']]\n",
    "    df_loss = pd.DataFrame(history.history).loc[:,['loss','val_loss']]\n",
    "\n",
    "    df_accuracy.plot(ax=ax[0])\n",
    "    df_loss.plot(ax=ax[1])\n",
    "    ax[0].set_ylim(0.5,1.05)\n",
    "    ax[1].set_ylim(-0.5,5)\n",
    "\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "deletable": false,
    "editable": false,
    "id": "529iDceSSb-V",
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "27dcab2b0d9b3baeddaed1fa8708301f",
     "grade": false,
     "grade_id": "cell-484e2cd383baa6aa",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "We can see that using a feature extractor did not prevent overfitting, but validation accuracy is better than for a small model with data augmentation from \"optional2_DataAugmentation.ipynb\" (accuracies are ~0.78-0.80 vs 0.70-0.75 respectively). In addition, the validation accuracy and loss are much more stable than with augmented data and learning is faster.\\\n",
    "Note, that we use low resolution images in this round (60x60 pixels), to reduce training time. For 150x150 pixel images test accuracy is as high as 0.95."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "deletable": false,
    "editable": false,
    "id": "R_W5RGEifapp",
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "c62a828f67cec4e4337cf0377bda5f50",
     "grade": false,
     "grade_id": "cell-a142802069580c3a",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "# 3.  Fine-tuning \n",
    "\n",
    "The first layers of the convolutional base encode more generic, reusable features like texture, corners, edges, and colour blobs, while layers higher up encode more specialized features like eye, nose, cloth item, etc. In order to improve the performance of the model even further, we can train (or **fine-tune**) the weights of the top layers of the pre-trained model alongside with training of the classifier we've added. This training process will force the weights to be tuned from generic feature maps to features associated specifically with the dataset we are using. However, we should be careful in choosing how many layers of the pre-trained model we want to fine-tune. The pre-trained model has millions of parameters, so the more parameters we are training, the more we are at risk of overfitting the training data, especially if our dataset is small.\n",
    "\n",
    "Another important thing to remember is that classifier we will be using during fine-tuning should be already trained. If we will add an untrained classifier on the top of the model and at the same time will unfreeze few layers of **conv_base**, the error propagating through the network will be too large and will destroy learned features of unfrozen layers. This is an unwanted outcome, as our aim is to fine-tune (make small changes) the weights of the convolutional base and not to learn them from the scratch.\n",
    "\n",
    "Summarizing, the steps for fine-tuning the pre-trained model are:\n",
    "\n",
    "1. Add classifier (dense layers) on the top of the pre-trained model\n",
    "2. Freeze ALL layers of the pre-trained model \n",
    "3. Train classifier\n",
    "4. Unfreeze FEW layers of the pre-trained model \n",
    "5. Train both, unfrozen layers of convolutional base and classifier"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "7fc38d2787ff057e1ba742805faa9d4a",
     "grade": false,
     "grade_id": "cell-b4023335942088e1",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "<div class=\" alert alert-warning\">\n",
    "    <h3><b>Student task. </b>Fine-tuning pre-trained model.</h3>\n",
    "   \n",
    "Your task is to:\n",
    "\n",
    "1. Load pre-trained (with ImageNet weights) conv base and freeze all layers \n",
    "2. Add classification head \n",
    "3. Compile and train model\n",
    "4. Unfreeze all conv_base layers\n",
    "5. Freeze all, but the last 4 layers\n",
    "6. Compile and train the model with small learning rate\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "447babc53f77bc2b5c2d0ab642909952",
     "grade": false,
     "grade_id": "cell-623140bfe42c03e7",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "First, let's create new generators where we enable sample shuffling."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "70acaba9ee64f38f91978fc6a0c0bf52",
     "grade": false,
     "grade_id": "cell-2c5efa3a9fab8434",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "train_ds = tf.data.Dataset.list_files(str(base_dir/'train/*/*.jpg'))\n",
    "val_ds   = tf.data.Dataset.list_files(str(base_dir/'validation/*/*.jpg'))\n",
    "test_ds  = tf.data.Dataset.list_files(str(base_dir/'test/*/*.jpg'))\n",
    "\n",
    "\n",
    "with tf.device('/cpu:0'):\n",
    "    # Set `num_parallel_calls` so multiple images are loaded/processed in parallel.\n",
    "    train_ds = train_ds.map(load_image, num_parallel_calls=AUTOTUNE)\n",
    "    val_ds = val_ds.map(load_image, num_parallel_calls=AUTOTUNE)\n",
    "    test_ds = test_ds.map(load_image, num_parallel_calls=AUTOTUNE)\n",
    "\n",
    "    train_ds = configure_for_performance(train_ds, shuffle=True)\n",
    "    val_ds   = configure_for_performance(val_ds)\n",
    "    test_ds  = configure_for_performance(test_ds)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "59ecc116671d32287783d64dbd9c1c01",
     "grade": false,
     "grade_id": "cell-169e084b7111a647",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "<div class=\" alert alert-warning\">\n",
    "    <i>1. Load pre-trained (with imagenet weights) conv base & freeze all layers.</i>\n",
    "</div>\n",
    "\n",
    "We've already loaded conv base with weights in the student task above. It should be stored in the `conv_base` variable and all layers should be frozen."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "d4ddc21072e90e729d95dd8183236e67",
     "grade": false,
     "grade_id": "cell-9ace02fea419d884",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "<div class=\" alert alert-warning\">\n",
    "    <i>2. Add classification head.</i>\n",
    "    \n",
    "Build a model containing:\n",
    "    \n",
    "- data augmentation layer (defined below)\n",
    "- conv base (re-use `conv_base`defined above)\n",
    "- classification head (re-use classification head `clf_head` trained above)\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "2d82bc0454a2f23f1daf26f52ad07c44",
     "grade": false,
     "grade_id": "cell-325dc8990d3b822e",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "from tensorflow.keras.layers.experimental.preprocessing import RandomFlip, RandomRotation, RandomZoom\n",
    "\n",
    "# data augmentation layer\n",
    "data_augmentation = tf.keras.Sequential(\n",
    "    [\n",
    "        RandomFlip(\"horizontal\", input_shape=(IMG_SIZE, IMG_SIZE, 3)),\n",
    "        RandomRotation(0.1, fill_mode='constant'),\n",
    "        RandomZoom(0.1,0.1, fill_mode='constant')\n",
    "    ]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "47f18f61e97c9a2110decede7ae14981",
     "grade": false,
     "grade_id": "cell-5a667e7e36d70246",
     "locked": false,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "# YOUR CODE HERE\n",
    "# raise NotImplementedError()\n",
    "\n",
    "model = tf.keras.Sequential() # create Sequential object\n",
    "model.add(data_augmentation)  # add data_augmentation layer\n",
    "model.add(conv_base)  # add conv_base\n",
    "model.add(clf_head)  # add clf_head"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "f3d6cd2fb39f9db730ffb859369b3b13",
     "grade": true,
     "grade_id": "cell-b37211c3d63e5c77",
     "locked": true,
     "points": 1,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "# this cell is for tests\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "08a406da6765ef3df738f653809f60eb",
     "grade": false,
     "grade_id": "cell-cf241ce28259b3f9",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "<div class=\" alert alert-warning\">\n",
    "    <i>3. Compile and train model.</i>\n",
    "    \n",
    "Set loss and metrics. Use RMSprop optimizer with default learning rate. Train model using training set (train_ds) and validation set (val_ds) for 5 epochs. \n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "435c143b7c24b3f5bb1c37b398ed4be1",
     "grade": false,
     "grade_id": "cell-d70a9ed430d2589b",
     "locked": false,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "# YOUR CODE HERE\n",
    "# raise NotImplementedError()\n",
    "\n",
    "# compile the model \n",
    "\n",
    "model.compile(optimizer=\"RMSprop\",loss='sparse_categorical_crossentropy',\n",
    "                 metrics='accuracy')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "d0917cb50c7f566b49849d3f4f82a86f",
     "grade": true,
     "grade_id": "cell-e83f241631bd804d",
     "locked": true,
     "points": 0.25,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "# this cell is for tests\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "fb937adab08e493fb48dc98d2860712b",
     "grade": true,
     "grade_id": "cell-1a13a190daa68156",
     "locked": true,
     "points": 0.25,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "# this cell is for tests\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "a4670598b4a0e2c6a71f9e3df981e821",
     "grade": false,
     "grade_id": "cell-a9fa541e12dbe008",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "<div class=\" alert alert-danger\">\n",
    "    <h3><center>WARNING: Training time ~ 15 min.</center></h3>    \n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "5aed28fc4ad0af89a470d9c9a1cadaa6",
     "grade": false,
     "grade_id": "cell-aeb258c087e49340",
     "locked": false,
     "schema_version": 3,
     "solution": true,
     "task": false
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 8 µs, sys: 2 µs, total: 10 µs\n",
      "Wall time: 19.8 µs\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "# model training \n",
    "if training:\n",
    "# YOUR CODE HERE\n",
    "# raise NotImplementedError()\n",
    "    history = model.fit(train_ds, validation_data=val_ds, epochs=5, verbose=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "9e3a9c421f3270dbb232039c42992b24",
     "grade": false,
     "grade_id": "cell-cd92d1e41de5f19a",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "Notice, that adding data augmentation layer result in decreasing of training accuracy from 1.0 to ~0.80, while validation accuracy did not change significantly. This is expected as data augmentation prevents the model overfitting training data."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "cce0546b9d71c1b6c9fc7843dea363d8",
     "grade": false,
     "grade_id": "cell-5683b897b89eaa34",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "<div class=\" alert alert-warning\">\n",
    "    <i>4. Unfreeze all conv base layers.</i>\n",
    "</div>\n",
    "\n",
    "After you pre-trained classifier unfreeze few layers of the convolutional base. Specifically, unfreeze the last four layers of the VGG-16 model **conv_base** (three convolutional + one pool layers). To do so, you can first unfreeze all layers by setting the parameter `trainable` as `True`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "deletable": false,
    "id": "BsjvfACSfaps",
    "nbgrader": {
     "cell_type": "code",
     "checksum": "afc8465441c1c995eef7f9f059126284",
     "grade": false,
     "grade_id": "cell-2c52aa0177724dc6",
     "locked": false,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "# unfreeeze all layers\n",
    "conv_base.trainable = True \n",
    "\n",
    "# YOUR CODE HERE\n",
    "# raise NotImplementedError()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "2040bd5458be1d554ac9a08009c1bbb6",
     "grade": false,
     "grade_id": "cell-2fc7c29901cb0288",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sanity check passed!\n"
     ]
    }
   ],
   "source": [
    "# Sanity check\n",
    "\n",
    "assert conv_base.trainable==True, \"Unfreeze all layers!\"\n",
    "print(\"Sanity check passed!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "1975649a5731d2a33087767018679f6a",
     "grade": true,
     "grade_id": "cell-ad85f978db5c4d90",
     "locked": true,
     "points": 1,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "# this cell is for tests\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "19c5814646c830ea3421c4e76cc9237b",
     "grade": false,
     "grade_id": "cell-e9a5318b1ca7f77c",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "<div class=\" alert alert-warning\">\n",
    "    <i>5. Freeze all conv base layers, except last 4.</i>\n",
    "</div>\n",
    "\n",
    "Set `layer.trainable` to False to all **but last 4 layers** by using for loop and iterating list `conv_base.layers`. Do not iterate the last 4 elements of the list as these last layers should remain trainable."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "874636663fa4e5f2c5ac39d4a6061da7",
     "grade": false,
     "grade_id": "cell-a562d9759c3dd9bf",
     "locked": false,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "# YOUR CODE HERE\n",
    "# raise NotImplementedError()\n",
    "numberOfLayersExceptFour = len(conv_base.layers) - 4\n",
    "# freeze all layers except the last 4 \n",
    "for i in range(0, numberOfLayersExceptFour):\n",
    "    conv_base.layers[i].trainable = False\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "ca3875f7c6410b1e52c0c5d3fdeb3ff3",
     "grade": false,
     "grade_id": "cell-b5449d7fe86ea6cd",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "You can check if `trainable` parameter is set correctly:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 359
    },
    "colab_type": "code",
    "deletable": false,
    "editable": false,
    "id": "w542wNGufap0",
    "nbgrader": {
     "cell_type": "code",
     "checksum": "81ba2f29f49d4f249a3dfc8ce5658beb",
     "grade": false,
     "grade_id": "cell-a1efff9c2873f23b",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    },
    "outputId": "cdba4c34-b2fc-457f-e8a8-e66b4ed99914"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<keras.engine.input_layer.InputLayer object at 0x7f48bc340a00>    False\n",
      "<keras.layers.convolutional.Conv2D object at 0x7f48bc340e20>    False\n",
      "<keras.layers.convolutional.Conv2D object at 0x7f48bc340e50>    False\n",
      "<keras.layers.pooling.MaxPooling2D object at 0x7f48bc349610>    False\n",
      "<keras.layers.convolutional.Conv2D object at 0x7f48bc41e760>    False\n",
      "<keras.layers.convolutional.Conv2D object at 0x7f48bc313070>    False\n",
      "<keras.layers.pooling.MaxPooling2D object at 0x7f48bc396fa0>    False\n",
      "<keras.layers.convolutional.Conv2D object at 0x7f48bc30cd60>    False\n",
      "<keras.layers.convolutional.Conv2D object at 0x7f48bc31f340>    False\n",
      "<keras.layers.convolutional.Conv2D object at 0x7f48bc319bb0>    False\n",
      "<keras.layers.pooling.MaxPooling2D object at 0x7f48bc2a94c0>    False\n",
      "<keras.layers.convolutional.Conv2D object at 0x7f48bc323b80>    False\n",
      "<keras.layers.convolutional.Conv2D object at 0x7f48bc2b09d0>    False\n",
      "<keras.layers.convolutional.Conv2D object at 0x7f48bc2a9880>    False\n",
      "<keras.layers.pooling.MaxPooling2D object at 0x7f48bc2ba3d0>    False\n",
      "<keras.layers.convolutional.Conv2D object at 0x7f48bc2baee0>    True\n",
      "<keras.layers.convolutional.Conv2D object at 0x7f48bc2b5c70>    True\n",
      "<keras.layers.convolutional.Conv2D object at 0x7f48bc2bebb0>    True\n",
      "<keras.layers.pooling.MaxPooling2D object at 0x7f48bc2c9760>    True\n"
     ]
    }
   ],
   "source": [
    "# print the trainable status of individual layers\n",
    "for layer in conv_base.layers:   print(layer,\"  \",  layer.trainable)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "deletable": false,
    "editable": false,
    "id": "AULPzcSUSb-j",
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "b1493616417e966d7f1829df0a0690aa",
     "grade": false,
     "grade_id": "cell-350da6b66acb7e73",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "The `True` flag indicates trainable layers and `False` - freezed layers."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "4c275b36096ae0443fe4abb74802aa3e",
     "grade": false,
     "grade_id": "cell-436cba3e6a38542d",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sanity check passed!\n"
     ]
    }
   ],
   "source": [
    "# Sanity check\n",
    "\n",
    "assert conv_base.layers[-5].trainable==False, \"14th layer should not be trainable!\"\n",
    "assert conv_base.layers[-4].trainable==True, \"15th layer should be trainable!\"\n",
    "print(\"Sanity check passed!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "0b7cd9fa006aa18d3deba5ab96f538a8",
     "grade": true,
     "grade_id": "cell-88f4ab3060d8be6e",
     "locked": true,
     "points": 0.75,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "# this cell is for tests\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "07a5c0b975a6fd159a6677229ae95447",
     "grade": true,
     "grade_id": "cell-5a0f70265777d6b7",
     "locked": true,
     "points": 0.75,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "# hidden test\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "2b5414075756f724c449ebac7460f652",
     "grade": true,
     "grade_id": "cell-b655f6cdbf566309",
     "locked": true,
     "points": 0.5,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "# hidden test\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "c7f57ca59764bdb58794c08ae9d5a296",
     "grade": false,
     "grade_id": "cell-b527664119512a00",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "<div class=\" alert alert-warning\">\n",
    "    <i>6. Compile and train model.</i>\n",
    "</div>\n",
    "\n",
    "Set loss and metrics. Train the model with the RMSprop optimizer, using a very low learning rate `lr=1e-5`. The reason for using a low learning rate is that we want to limit the magnitude of the modifications we make to the representations of the 3 convolutional layers that we are fine-tuning. Updates that are too large may harm these representations.\n",
    "\n",
    "Set parameter  of `.fit()` function `initial_epoch = initial_epochs`, where `initial_epochs` is set to 5. This parameter specifies the epoch at which to start training. We do not randomly initialize the weight of our dense layers, rather the classifier inherits the weights learned from earlier training. Previously we trained the network for 5 epochs, therefore we will use weights learned at the end of the 5th epoch for our classifier. We will further train the model for more 10 epochs (variable `fine_tune_epochs`). Set `epochs`  to `total_epochs` variable, which is a sum of `initial_epochs` and `fine_tune_epochs` and equals in our case to 15 .\n",
    "\n",
    "Save trained model as `model_fine_tune.h5`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "deletable": false,
    "editable": false,
    "id": "zFFY5vsUfaqL",
    "nbgrader": {
     "cell_type": "code",
     "checksum": "88d0a47577ef39eff99d619c142683f1",
     "grade": false,
     "grade_id": "cell-36dd87792bb05148",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "initial_epochs   = 5 # number of epoch we used to train the classifier earlier\n",
    "fine_tune_epochs = 10 # fine-tune the model for 10 epochs (in addition to previous 5 epochs)\n",
    "total_epochs     =  initial_epochs + fine_tune_epochs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "0e228bbd9052de34927358a5bccade7f",
     "grade": false,
     "grade_id": "cell-4f70ff9c00e31581",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "<div class=\" alert alert-danger\">\n",
    "    <h3><center>WARNING: Training time ~ 30 min.</center></h3>    \n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "deletable": false,
    "id": "0jUrUyvBfaqH",
    "nbgrader": {
     "cell_type": "code",
     "checksum": "e667df94062828bfb662246dcd6fc925",
     "grade": false,
     "grade_id": "cell-665b73322a83a29b",
     "locked": false,
     "schema_version": 3,
     "solution": true,
     "task": false
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 5.81 ms, sys: 427 µs, total: 6.24 ms\n",
      "Wall time: 5.26 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "# compile and train the model\n",
    "\n",
    "model.compile(optimizer=tf.keras.optimizers.RMSprop(learning_rate=1e-5),loss='sparse_categorical_crossentropy',metrics='accuracy')\n",
    "if training:\n",
    "# YOUR CODE HERE\n",
    "# raise NotImplementedError()\n",
    "    history = model.fit(train_ds, validation_data=val_ds, initial_epoch = initial_epochs, epochs=total_epochs, verbose=1)\n",
    "    model.save(\"model_fine_tune.h5\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "deletable": false,
    "editable": false,
    "id": "G5RCUWuDTWCt",
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "6b08bc9aaa199d37b07b7d0139e5a9e1",
     "grade": false,
     "grade_id": "cell-391b9dafe199c198",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "Now we will plot accuracy and loss for all epochs - 5 epochs of training while using the pre-trained network as feature extractor and 10 epochs while fine-tuning pre-trained model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "deletable": false,
    "editable": false,
    "id": "MbZ5f3M5kaue",
    "nbgrader": {
     "cell_type": "code",
     "checksum": "8863de34f1a7ea5b80eb666faec63f8a",
     "grade": false,
     "grade_id": "cell-2fd07651fd33d0d4",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "# second if statement is to prevent multiple re-runs of the cells\n",
    "\n",
    "if training:\n",
    "    if len(history.history['accuracy']) == initial_epochs:\n",
    "        # add accuracy and loss of fine-tuned model \n",
    "        # to the result obtained in step \"3. Compile and train model.\"\n",
    "        history.history['accuracy'] += history_fine_tune.history['accuracy']\n",
    "        history.history['val_accuracy'] += history_fine_tune.history['val_accuracy']\n",
    "\n",
    "        history.history['loss'] += history_fine_tune.history['loss']\n",
    "        history.history['val_loss'] += history_fine_tune.history['val_loss']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "deletable": false,
    "editable": false,
    "id": "q3wtTVfeZ80r",
    "nbgrader": {
     "cell_type": "code",
     "checksum": "d7afb10a38544aedb57e30c0bfa1710c",
     "grade": false,
     "grade_id": "cell-adb855b0584230b9",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "# retrieve results on training and validation data\n",
    "# for all epochs\n",
    "\n",
    "if training:\n",
    "    acc      = history.history['accuracy']\n",
    "    val_acc  = history.history['val_accuracy']\n",
    "    loss     = history.history['loss']\n",
    "    val_loss = history.history['val_loss']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 513
    },
    "colab_type": "code",
    "deletable": false,
    "id": "TvOMFwCKAQ5j",
    "nbgrader": {
     "cell_type": "code",
     "checksum": "e72a782ca45bd73445c2769204f5948e",
     "grade": false,
     "grade_id": "cell-24cf96c1fbd83910",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    },
    "outputId": "7d4e6010-a0e9-44be-aa75-1654d979689a"
   },
   "outputs": [],
   "source": [
    "if training:\n",
    "    epochs=total_epochs\n",
    "    print(len(acc))\n",
    "    print(epochs)\n",
    "    test_loss, test_acc = model.evaluate(test_ds)\n",
    "    print(f'The test set accuracy of model is {test_acc:.2f}')\n",
    "\n",
    "    plt.figure(figsize=(8, 8))\n",
    "    epochs = range(1,total_epochs+1,1)\n",
    "\n",
    "    # plot accuracy\n",
    "    plt.subplot(2, 1, 1)\n",
    "    plt.plot(epochs, acc, label='Training')\n",
    "    plt.plot(epochs, val_acc, label='Validation')\n",
    "    plt.plot([initial_epochs,initial_epochs],    # plot vertical line\n",
    "              plt.ylim(), '--k', label='Start Fine Tuning') # indicating the start of fine-tuning\n",
    "\n",
    "    plt.tick_params(labelbottom=False)\n",
    "    plt.legend()\n",
    "    plt.title('Accuracy')\n",
    "\n",
    "    # plot loss\n",
    "    plt.subplot(2, 1, 2)\n",
    "    plt.plot(epochs,loss)\n",
    "    plt.plot(epochs, val_loss)\n",
    "    plt.plot([initial_epochs,initial_epochs],    # plot vertical line\n",
    "             plt.ylim(), '--k', label='Start Fine Tuning')  # indicating the start of fine-tuning\n",
    "\n",
    "    plt.title('Loss')\n",
    "    plt.xlabel('epoch')\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "61508e3d56e921afd2e693c678b93b9b",
     "grade": false,
     "grade_id": "cell-2b0f9df1cac3b390",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "We can see that although fine-tuning leads to further overfitting at the end of the training, it has also slightly improved the accuracy of the test dataset from 0.80 to approximately ~0.83. You may further improve the accuracy by training longer (e.g. with Colab GPU) or trying larger learning rate, e.g. 1e-4.\\\n",
    "The overfitting of the network is not necessarily a bad thing and may actually indicate that model can be improved by adjusting hyperparameters or adding regularization."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "deletable": false,
    "editable": false,
    "id": "O3v3aiutfaqY",
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "6104681cc01d678d86a1402b5b9da75e",
     "grade": false,
     "grade_id": "cell-830311b5ef84fb1c",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "<div class=\"wrap-up\">\n",
    "    <div class=\"wrap-up-title\">Wrap up</div><br>\n",
    "    <div class=\"wrap-up-content\">\n",
    "        <ul>\n",
    "          <li>We demonstrated the advantage of transfer learning for smaller data-set applications. By reusing a pre-trained model we can get much better accuracy than with a classifier trained from scratch. </li>\n",
    "          <li> While using a pre-trained model as a feature extractor, the pre-trained model is \"frozen\" and only the weights of the newly added classifier get updated during training. </li>\n",
    "          <li>In the case of the small data, feature extraction with image augmentation helps to avoid overfitting but comes at the cost of higher computational power.</li>\n",
    "          <li>Fine-tuning helps to adjust the weights such that the network is more specific to the new dataset and thus improves the performance of the model a bit further.</li>\n",
    "        </ul>\n",
    "    </div>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "9d297bc217dd777b824459cfb528ee4e",
     "grade": false,
     "grade_id": "cell-b2919b295f561c8a",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "<div class=\" alert alert-warning\">\n",
    "    <h3>Question 1.</h3>\n",
    "\n",
    "The main idea of fine-tuning pre-trained model is :\n",
    "\n",
    "1. To use the weights learned by training on a large dataset, which is different from the actual training dataset of your application (but of similar type), as the initialization for the training. \n",
    "\n",
    "2. To use the weights learned by the network on a smaller reference dataset without further tuning them on the target dataset. \n",
    "\n",
    "3. To train a large neural net with initializing all weights to zero. \n",
    "    \n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "5767242d5b43ca37126f5d6ac6952d65",
     "grade": false,
     "grade_id": "cell-aa7f2076259ffcaf",
     "locked": false,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "# remove the line raise NotImplementedError() before testing your solution and submitting code\n",
    "\n",
    "# YOUR CODE HERE\n",
    "# raise NotImplementedError()\n",
    "\n",
    "answer_1 = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "f8b1b630f3f26830ab89129dd3204d4e",
     "grade": true,
     "grade_id": "cell-f3a0a9843a7e39a1",
     "locked": true,
     "points": 0.25,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sanity check tests passed!\n"
     ]
    }
   ],
   "source": [
    "# This cell is for tests\n",
    "assert answer_1 in [1,2,3], '\"answer\" Value should be an integer between 1 and 3.'\n",
    "print('Sanity check tests passed!')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "b535b173067b39eed65ab9f60d70232b",
     "grade": false,
     "grade_id": "cell-005c5d8dbdd77ccf",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "<div class=\" alert alert-warning\">\n",
    "    <h3>Question 2.</h3>\n",
    "\n",
    "Transfer learning is based on using a pre-trained neural net. Which of the following statement is correct? \n",
    "\n",
    "1. Transfer learning works only if the target dataset is larger than the dataset used to obtain the pre-trained neural net. \n",
    "\n",
    "2. Transfer learning works only for image data.  \n",
    "\n",
    "3. The pre-trained neural net should be trained on data with similar statistical properties as the target data.     \n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "636229f9f9aaf2c11d3673d59053f3d6",
     "grade": false,
     "grade_id": "cell-bc24032e03c36a2f",
     "locked": false,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "# remove the line raise NotImplementedError() before testing your solution and submitting code\n",
    "\n",
    "# YOUR CODE HERE\n",
    "# raise NotImplementedError()\n",
    "\n",
    "answer_2 = 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "aeb476d9fca4c81f4cf142fa1afab593",
     "grade": true,
     "grade_id": "cell-8f9b33504de63909",
     "locked": true,
     "points": 0.25,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sanity check tests passed!\n"
     ]
    }
   ],
   "source": [
    "# This cell is for tests\n",
    "assert answer_2 in [1,2,3], '\"answer\" Value should be an integer between 1 and 3.'\n",
    "print('Sanity check tests passed!')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "5abd129631d2b8b7a5425cf1ac01a0de",
     "grade": false,
     "grade_id": "cell-66014efb5e622fe2",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "<div class=\" alert alert-warning\">\n",
    "    <h3>Question 3.</h3>\n",
    "\n",
    "The fastest way to use a pre-trained model is:\n",
    "\n",
    "1. Unfreeze few convolutional base layers and train these layers with classifier on target data\n",
    "\n",
    "2. Separately extract features of target data from the convolutional base of the pre-trained model and feed them to the classifier\n",
    "\n",
    "3. Use a frozen convolutional base of the pre-trained model and train only layers of the classifier by passing the target data through the whole network\n",
    "\n",
    "4. Unfreeze all layers of pre-trained model and train with target data   \n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "6706ff44d06ca85b8dc0b36c0a8607b3",
     "grade": false,
     "grade_id": "cell-34ffa9f9e5b32fd2",
     "locked": false,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "# remove the line raise NotImplementedError() before testing your solution and submitting code\n",
    "\n",
    "# YOUR CODE HERE\n",
    "# raise NotImplementedError()\n",
    "\n",
    "answer_3 = 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "ab63502854e45e4529d89180a339b595",
     "grade": true,
     "grade_id": "cell-61bbe83d3c0a03fd",
     "locked": true,
     "points": 0.25,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sanity check tests passed!\n"
     ]
    }
   ],
   "source": [
    "# This cell is for tests\n",
    "assert answer_3 in [1,2,3,4], '\"answer\" Value should be an integer between 1 and 4.'\n",
    "print('Sanity check tests passed!')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "756c4b9d7940f93f1893f23ccad710b6",
     "grade": false,
     "grade_id": "cell-0d054864c0d4ee16",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "<div class=\" alert alert-warning\">\n",
    "    <h3>Question 4.</h3>\n",
    "    \n",
    "It is better to unfreeze few last layers of the convolutional base when the data used for training pre-trained network and target data are:\n",
    "\n",
    "1. of different types (very different)\n",
    "\n",
    "2. highly similar\n",
    "\n",
    "3. somewhat similar\n",
    "    \n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "7dd9a8f8ad746b81509ccbb0f96ef11e",
     "grade": false,
     "grade_id": "cell-67fee9b4e181fa8b",
     "locked": false,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "# remove the line raise NotImplementedError() before testing your solution and submitting code\n",
    "\n",
    "# YOUR CODE HERE\n",
    "# raise NotImplementedError()\n",
    "\n",
    "answer_4 = 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "4b2b21952324c687db01c4439e310901",
     "grade": true,
     "grade_id": "cell-a7b25193fef7796d",
     "locked": true,
     "points": 0.25,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sanity check tests passed!\n"
     ]
    }
   ],
   "source": [
    "# This cell is for tests\n",
    "assert answer_4 in [1,2,3], '\"answer\" Value should be an integer between 1 and 3.'\n",
    "print('Sanity check tests passed!')\n"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "celltoolbar": "Edit Metadata",
  "colab": {
   "name": "Transfer_Learning.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.5"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": false,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {
    "height": "calc(100% - 180px)",
    "left": "10px",
    "top": "150px",
    "width": "333.854156px"
   },
   "toc_section_display": true,
   "toc_window_display": true
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
